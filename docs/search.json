[
  {
    "objectID": "extinction_modelling.html",
    "href": "extinction_modelling.html",
    "title": "Heading to extinction?",
    "section": "",
    "text": "The vulnerability of a species to extinction is dependant upon many life history parameters and other factors, such as:\n\nBody size\nThermal tolerance\nSpeciality/generality of feeding or habitat preference\nGrowth rate\nProductivity\nMigration ability\nCurrent population size\n\nFocusing on one of these, thermal tolerance, we hypothesise that cooler species are being driven out from regions due to warming waters. Looking at Figure 1, we see that cooler species are generally declining in the southern parts of Australia, whilst warmer species are remaining consistent or increasing (in Tasmania at least).\n\n\n\nFigure 1: Mean population trends for cool-temperate, warm-temperate and tropical species in six geographic regions around Australia over the last 10 years. Image from Edgar et al (Accepted for publication, 2023).\n\n\nThis leads to the question:\nWhat happens to the cool-affinity species in Tasmania when the waters warm?"
  },
  {
    "objectID": "extinction_modelling.html#background",
    "href": "extinction_modelling.html#background",
    "title": "Heading to extinction?",
    "section": "",
    "text": "The vulnerability of a species to extinction is dependant upon many life history parameters and other factors, such as:\n\nBody size\nThermal tolerance\nSpeciality/generality of feeding or habitat preference\nGrowth rate\nProductivity\nMigration ability\nCurrent population size\n\nFocusing on one of these, thermal tolerance, we hypothesise that cooler species are being driven out from regions due to warming waters. Looking at Figure 1, we see that cooler species are generally declining in the southern parts of Australia, whilst warmer species are remaining consistent or increasing (in Tasmania at least).\n\n\n\nFigure 1: Mean population trends for cool-temperate, warm-temperate and tropical species in six geographic regions around Australia over the last 10 years. Image from Edgar et al (Accepted for publication, 2023).\n\n\nThis leads to the question:\nWhat happens to the cool-affinity species in Tasmania when the waters warm?"
  },
  {
    "objectID": "extinction_modelling.html#the-approach",
    "href": "extinction_modelling.html#the-approach",
    "title": "Heading to extinction?",
    "section": "The approach",
    "text": "The approach\n1. It starts with an observation or idea:\n“Has anyone noticed how we’ve started seeing a heap more warm-affinity fish in our dives around Bicheno?”.\n2. Leading into a formal hypothesis or question:\nWhat are the population trends of fish species across Tassie in the past decade, and how is that related to the thermal affinity of the species?\n3. Thinking about how we might analyse this:\nFor a single species, we could look at the abundance of each species over time - this could give us an idea about whether that species is going up, down, or remaining constant.\n\n\n\nFigure 2: Back-of-envelope analysis of a single species population trend over time. Where a species may be increasing (orange), remaining constant (green), or declining (black).\n\n\nThe rate of decline in abundance over time can give us an idea about how quickly the species is heading to ‘extinction’ (Figure 3).\n\n\n\nFigure 3: Some species may decline more rapidly (species B) than others (species A). Is species B at greater risk of extinction?"
  },
  {
    "objectID": "extinction_modelling.html#todays-practical",
    "href": "extinction_modelling.html#todays-practical",
    "title": "Heading to extinction?",
    "section": "Today’s practical",
    "text": "Today’s practical\nEdgar et al (Accepted, 2023) looked at the species trends for 1057 species. In this practical we will look at a random selection of 20 of those species. The steps we will follow are:\n\nGet general life history information about each species, e.g. mean or maximal body size of the species, thermal preference.\nGet fish abundance data from from the Reef Life Survey (RLS)\nUse R to analyse and quantify population trends.\n\n\nStep 1. Getting life-history data\nTry and get as much information about the species as possible. Sources include:\n\nFishbase\nWikipedia\nIUCN\nReef Life survey\nChatGPT - ask for a reference/source and check that source!\n\nWe will split into pairs. Each pair will try to get as much life-history information as possible. Input your data into the Google Doc here.\n\n\nStep 2. Getting abundance data\n\nTry and access the survey data from https://www.reeflifesurvey.com, which will take you over to the AODN portal (Figure 4):\n\n\n\n\nFigure 4: Screen shot of the data extract we want\n\n\n\n\nStep 3. Analysis in R\n\nDownload R (https://cran.r-project.org/)\nDownload R-Studio (https://posit.co/downloads/)\nSet-up a new project\nRead in data\nFit a linear model of abundance as a function of time.\n\n\nWorking in projects in R\nTLDR; work in projects, your life will be easier.\nYou can think of projects as a folder (aka. working directory) where you would keep all your input data, output figures, output summary data etc.\nWorking in projects makes your coding life much easier. R knows where to look for things, R knows where to output things, and everything is organised…you will thank yourself later.\nSteps:\n\nLocate or create a file in your documents where you want to put all your R projects. For example I keep mine in “Documents/Work/R_projects/”.\nOpen R studio\nCreate a new project, call it something useful, e.g. “ksm718_extinction_prac” or “ksm718_prac2”, avoid using spaces or capitals, instead use “_”.\n\nNote: When you open up the project in the future, just click on the .Rproj file, this will make sure you are actually working in that project. You can see which project you’re working in at the top right of your Rstudio. See Figure 5.\n\n\n\nFigure 5: Working in projects in Rstudio, here the project name is “extinction_modelling”.\n\n\n\n\nOpen a new script\nTLDR; work in scripts, not in the console.\nYou can code directly into the console, and it will work, but it won’t keep track of all your code. Sometimes I code directly into the console if I just want a quick answer for something, e.g.\n\n5*(6/9)\n\n[1] 3.333333\n\n\nWhen you write in scripts, you can “send” that code to the console to run, and you can save the script and come back to it later. Not only is that important when working on big R projects, but its important when you come to publishing your code when you publish a paper.\nTo begin, write something in the R script, maybe start with a comment (use “#” to signifiy a comment - R will ignore any text after a hashtag), then save the R file.\n\n# R script to analyse trends of species abundance\n\n\n\nGetting the data into R\nFrom Edgar et al (Accepted, 2023), I have randomly selected 20 Tasmanian species. I have called this file is called “count_data_20spp.csv”.\nI have put the data into a Google Sheet, you can download it here. Copy these data, and paste them into Excel, and save the document as a comma separated value files (.csv) file.\nR likes .csv files, it does not like .xlsx files as they have heaps of extra information that Excel uses and that R does not care about (e.g. colours of excel cells, date formats etc.). R just wants the raw data, nothing else.\n\nPutting the raw data where R can access it\nCreate a new folder in the project directory, you can either do that in R studio or you can actually locate the folder on your computer and create a new folder there. I am going to call this folder “data” (you could call it anything that makes sense to you and your organisation, maybe you want to call it “input” or “raw_data”). Basically this is to organise your files and keep all your data together.\nHere we are only using a single data file, but it may be the case you have hundreds or thousands, and that’s where this organisation will benefit you heaps.\nBecause we are working in projects, R already knows where to look (the location of the .Rproj file).\nFirst step is putting the raw data into the folder we just created (“data” or “input” or whatever you called it).\nNow lets read in the data…\n\n\nCoding\nThe first thing to normally do with a new script is to load the tidyverse package. This package is actually a collection of packages, and is just a lot of code that has been developed to make coding in R much more friendly. It is the new approach to coding in R and its much better to learn ‘the tidyverse way’. People talk about “Base R” vs “the Tidyvese”, you will ultimately learn both. But start with the tidyverse.\n\n# If you have not installed the tidyverse on your computer before, uncomment the line below and install it. You only need to do that once. You can remove it from your script after you've done that. \n# install.packages(\"tidyverse\")\n\n# once installed we can load the package\n# we need to do this every time we use any tidyverse code, so leave that line at the top of your scripts\nlibrary(tidyverse)\n\nNow we can read in the csv file using the tidyverse function called read_csv().\n\n# because I put the raw data into a folder called \"data\" I need to tell R to look in that folder for the file.\nread_csv(\"data/count_data_20spp.csv\")\n\n# A tibble: 46,950 x 6\n   site_code latitude longitude species_name    year   count\n   &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n 1 BI-S1        -41.9      148. Aracana aurita  1992  0     \n 2 BI-S1        -41.9      148. Aracana aurita  1993  0.0312\n 3 BI-S1        -41.9      148. Aracana aurita  1994  0     \n 4 BI-S1        -41.9      148. Aracana aurita  1995 NA     \n 5 BI-S1        -41.9      148. Aracana aurita  1996 NA     \n 6 BI-S1        -41.9      148. Aracana aurita  1997  0.0312\n 7 BI-S1        -41.9      148. Aracana aurita  1998 NA     \n 8 BI-S1        -41.9      148. Aracana aurita  1999  0     \n 9 BI-S1        -41.9      148. Aracana aurita  2000  0     \n10 BI-S1        -41.9      148. Aracana aurita  2001  0     \n# i 46,940 more rows\n\n\nThis will read the csv file and show it on the screen (thankfully it won’t show us the whole 49K rows), but we want to assign it to an object so that we can use the file and manipulate it, or summarise it, or visualise it.\n\nraw_dat &lt;- \n  read_csv(\"data/count_data_20spp.csv\")\n\n\n\nThinking about NA values\nIn this dataset, we have zero values, and we have NA values. How we deal with NA values is an important thing to consider in the analysis, were there really zero individuals observed or were they not counted? In this dataset 0 values correspond to if a species has been previously observed at that site, and the site was surveyed and none were spotted, then it is a zero. NA values here correspond to the site not being surveyed in that year.\nFirst lets get rid of the years where the sites were not surveyed (NA values). We go from 49K rows to 14K rows, a lot more friendly.\n\n# Removing rows that have an NA in the count column\ndat_no_na &lt;- \n  raw_dat |&gt; \n  drop_na(count)\n\nFirst thing before we start analyses, plot the data! Let’s take one species, e.g. Aracana aurita.\n\n# 980 rows\ndat_one_spp &lt;- \n  dat_no_na |&gt; \n  filter(species_name == \"Aracana aurita\") |&gt; \n  mutate(log_count = log(count + 1))\n\nThere are lots of rows, as each site has its own time-series. How about we look at the time series for each site in a big plot?\n\ndat_one_spp |&gt; \n  filter(str_detect(site_code, \"TI-S|TN\")) |&gt; # selecting a few sites only\n  ggplot() +\n  aes(x = year, \n      y = log_count) + \n  geom_path()  +\n  # seperate the data into a window (facet) for each site_code \n  facet_wrap(~site_code, \n             scales = \"free_y\")\n\n\n\n\nFigure 6: Population trends for Aracana aurita at six sites (a random subset).\n\n\n\n\nSome time series are only a few data points in length, probably not that informative, I would not be confident to say, for example, that the Aracana aurita is increasing at TN-S9 (Figure 6).\nOne way to overcome this is to take an average across the sites (Figure 7).\n\ndat_one_spp_mean &lt;- \n  dat_one_spp |&gt; \n  group_by(year) |&gt; \n  summarise(mean_log_count = mean(log_count))\n\n# average across all sites\ndat_one_spp_mean |&gt; \n  ggplot() +\n  aes(x = year, \n      y = mean_log_count) + \n  geom_point() +\n  geom_path()\n\n\n\n\nFigure 7: Mean population trends for Aracana aurita across all sites\n\n\n\n\nWhat is this species doing? Firstly it seems to be all over the place, but it does seem that in recent years it’s lower. Is this significant? Let’s see.\nFor now, we will convert all zero values to NA values.\n\nlm1 &lt;- lm(mean_log_count ~ year, data = dat_one_spp_mean) \n\nsummary(lm1)\n\n\nCall:\nlm(formula = mean_log_count ~ year, data = dat_one_spp_mean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.05612 -0.03559 -0.01990  0.02523  0.12288 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  1.0971236  2.1638202   0.507    0.616\nyear        -0.0005005  0.0010783  -0.464    0.646\n\nResidual standard error: 0.05098 on 27 degrees of freedom\nMultiple R-squared:  0.007916,  Adjusted R-squared:  -0.02883 \nF-statistic: 0.2154 on 1 and 27 DF,  p-value: 0.6463\n\n\nNo significant slope, i.e. no increase or decline. However, by taking an average of all of the sites, we are removing a lot of data. We could also use a linear mixed effects model to model this time-series.\n\n# This package allows us to get a p-value from the model\n# We can talk more about the appropriateness of getting a p-value from a mixed model\nlibrary(lmerTest)\n\nlmer1 &lt;- lmerTest::lmer(log_count ~ year + (1|site_code), data = dat_one_spp) \nsummary(lmer1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: log_count ~ year + (1 | site_code)\n   Data: dat_one_spp\n\nREML criterion at convergence: -787.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6443 -0.4597 -0.2005  0.2015  6.6786 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n site_code (Intercept) 0.01148  0.1072  \n Residual              0.02205  0.1485  \nNumber of obs: 980, groups:  site_code, 98\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(&gt;|t|)   \n(Intercept)  3.878e+00  1.197e+00  9.007e+02   3.241  0.00124 **\nyear        -1.876e-03  5.959e-04  9.001e+02  -3.147  0.00170 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nyear -1.000\n\n\nBy including all the data, we have a significant decline in the count of the species (Figure 8).\n\n# Extracting the slope and intercept from the lmer\nintercept_value &lt;- coef(summary(lmer1))[1, 1]\nslope_value &lt;- coef(summary(lmer1))[2, 1]\n\n\ndat_one_spp |&gt; \n  ggplot(aes(x = year, \n             y = log_count)) +\n  geom_point(col = \"grey\") + \n  geom_line(aes(group = site_code), \n            col = \"grey\") +\n  geom_abline(intercept = intercept_value,\n              slope = slope_value, \n              size = 2, \n              col = \"red\") +\n  theme_classic(20) +\n  labs(\n    x = \"Year\",\n    y = \"log(count)\"\n  )\n\n\n\n\nFigure 8: Overall population trends for Aracana aurita, accounting for the variability between sites and showing a fitted linear mixed effects model (red line).\n\n\n\n\n\n\n\n\nDiscussion\n\nWhy does the linear model slope differ from the linear mixed model slope?\nWhat are some immediate thoughts when you visualised the data?\nIs the result unexpected?\nWhat does the intercept value represent in the models?\nWhat does the slope value represent (in words)?\nDo you trust the result?\nWhat other modelling approaches could we do?\nCan we extrapolate from this linear model into the future?\nIs removing the NA values appropriate?\nIs removing the zero values appropriate?\n\n\n\nContact\n\n\n\n\n\n\n\n\n\nFreddie Heather,\nDemonstrator\nfreddie.heather@utas.edu.au\n\n\n\nJemina Stuart-Smith,\nUnit coordinator\nJemina.StuartSmith@utas.edu.au\n\n\n\n*Any typos or errors in this document; email freddie.heather@utas.edu.au"
  }
]